{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qFkxsrNw3oJb",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RgNljUK63oJh",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "Задача переноса стиля на изображении\n",
    "=============================\n",
    "\n",
    "\n",
    "Введение\n",
    "------------\n",
    "\n",
    "В этом ноутбуке мы реализуем алгоритм переноса стиля из статьи https://arxiv.org/abs/1508.06576 Leon A. Gatys, Alexander S. Ecker, Matthias Bethge.\n",
    "\n",
    "Перенос стиля (Neural-Style, Neural-Transfer) --- это процесс преобразования стиля исходного изображения к стилю выбранного изображения.\n",
    "\n",
    "***Основной идеей алгоритма, описанного в ноутбуке, является то, что\n",
    "признаки, полученные с помощью сверточной нейронной сети, можно использовать\n",
    "для выделения содержательной и стилевой составляющих изображения.***\n",
    "\n",
    "На вход алгоритму требуется три изображения:\n",
    "* input-image - изменяемое входное изображение (обычно берется исходное изображение или белый шум)\n",
    "* content-image - исходное изображение\n",
    "\n",
    "* style-image - изображение, стиль которого будет использован\n",
    "\n",
    "\n",
    "Алгоритм изменяет input-image таким образом, чтобы содержание было похоже на content-image, а стиль - на style-image.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B7dQ4off3oJi",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Формализация идеи\n",
    "--------------------\n",
    "\n",
    "Мы определяем два расстояния (метрики):\n",
    "* $D_C$ - расстояние между содержанием на изображениях (content distance)\n",
    "* $D_S$ - расстояние между стилями на изображениях (style distance)\n",
    "\n",
    "Затем берём изменяемое изображение (input-image) и трансформируем его так, чтобы на результирующем изображении минимизровались оба расстояния.\n",
    "\n",
    "\n",
    "Импортируем необходимые библиотеки\n",
    "-----------------------------------------\n",
    "\n",
    "-  ``torch``, ``torch.nn``, ``numpy``\n",
    "-  ``torch.optim``\n",
    "-  ``PIL``, ``PIL.Image``, ``matplotlib.pyplot`` (загрузка и визуализация изображений)\n",
    "-  ``torchvision.transforms`` (трансформирует PIL-изображения в тензоры)\n",
    "-  ``torchvision.models`` \n",
    "-  ``copy`` \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jDzhLWEa3oJi",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wajvcmfp3oJi",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Если возможно - запускаем алгоритм на GPU для ускорения вычислений:\n",
    "``torch.cuda.is_available()``\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "izbOqdNz3oJj",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e7e3IFF-3oJj",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Загружаем изображения\n",
    "\n",
    "------------------\n",
    "\n",
    "Загружаем стилевое изображение и изменяемое (content) изображение.\n",
    "\n",
    "Исходные PIL-картинки содержат значения от 0 до 255, однако при их преобразовании в тензоры значения переходят на отрезок от 0 до 1.\n",
    "\n",
    "Также изображения должны быть приведены к одинаковым размерам.\n",
    "\n",
    "***Важно!*** В pytorch значения тензоров должны лежать на отрезке от 0 до 1. Если попробовать применить модель к тензору со значениями от 0 до 255, то в результате применения свёрток (feature maps) не получится корректно выделить содержание и стиль на изображении."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B-QmDVPn3oJj",
    "outputId": "df50a4ff-868d-4112-f9b0-a2451e72fa55",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Определим размер картины. Важно - чем больше размер, тем дольше будет перенос стиля. Используйте GPU.\n",
    "imsize = 1024  \n",
    "\n",
    "loader = transforms.Compose([\n",
    "    transforms.Resize(imsize),  # изменение размеров изображения\n",
    "    transforms.ToTensor()])  # переводим картинку в тензор\n",
    "\n",
    "\n",
    "def image_loader(image_name):\n",
    "    image = Image.open(image_name)\n",
    "    image = loader(image).unsqueeze(0)\n",
    "    return image.to(device, torch.float)\n",
    "\n",
    "!wget https://pytorch.org/tutorials/_static/img/neural-style/picasso.jpg\n",
    "!wget https://pytorch.org/tutorials/_static/img/neural-style/dancing.jpg\n",
    "\n",
    "style_img = image_loader(\"picasso.jpg\") # поместите сюда путь к картине, стиль которой хотите перенести\n",
    "content_img = image_loader(\"dancing.jpg\") # поместите сюда путь к картине, содержание которой хотите перенести\n",
    "\n",
    "assert style_img.size() == content_img.size(), \\\n",
    "    \"we need to import style and content images of the same size\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tGPfyFiO3oJk",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Создадим функцию, которая визуализирует изображение, копируя его и переводя обратно в PIL формат.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 545
    },
    "id": "zx7oDIRS3oJk",
    "outputId": "76fa2d6d-497c-4247-8dff-84b9b0a186b0",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "unloader = transforms.ToPILImage() \n",
    "\n",
    "plt.ion()\n",
    "\n",
    "def imshow(tensor, title=None):\n",
    "    image = tensor.cpu().clone() \n",
    "    image = image.squeeze(0)      \n",
    "    image = unloader(image)\n",
    "    plt.imshow(image)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001) \n",
    "\n",
    "\n",
    "plt.figure()\n",
    "imshow(style_img, title='Style Image')\n",
    "\n",
    "plt.figure()\n",
    "imshow(content_img, title='Content Image')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6h8Q_7--3oJk",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Функции потерь (Loss)\n",
    "--------------\n",
    "\n",
    "***Content Loss***\n",
    "\n",
    "Content loss - взвешенный вариант content distance ($D_C$) для каждого свёрточного слоя сети.\n",
    "* принимает на вход feature maps $F_{XL}$ для изображения $X$ и слоя $L$ сети\n",
    "* возвращает взвешенное рассстояние $w_{CL}.D_C^L(X,C)$ между изображением $X$ и контентным изображением $C$.\n",
    "\n",
    "Feature maps контентного изображения ($F_{CL}$) должны быть известны заранее для вычисления контентного расстояния:\n",
    "$$D_C^L(X,C)=\\|F_{XL} - F_{CL}\\|^2$$ (для вычисления используем ``nn.MSELoss``).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cdpWcg8_3oJl",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class ContentLoss(nn.Module):\n",
    "\n",
    "    def __init__(self, target,):\n",
    "        super(ContentLoss, self).__init__()\n",
    "        self.target = target.detach()\n",
    "\n",
    "    def forward(self, input):\n",
    "        self.loss = F.mse_loss(input, self.target)\n",
    "        return input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uXosdrWs3oJm",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Style Loss**\n",
    "\n",
    "Модуль Style loss выглядит похожим образом.\n",
    "\n",
    "Чтобы вычислить style loss, необходимо вычислить матрицу Грама (матрицу скалярных произведений) $G_{XL}$. Матрица Грама - это результат умножения матрицы на её транспонированный вариант. \n",
    "\n",
    "В данном случае нам нужна матрица feature maps $F_{XL}$ для слоя $L$. Мы трансформируем матрицу $F_{XL}$, чтобы она имела размерность $K \\times N$, где \n",
    "* $K$ - число feature maps на слое $L$\n",
    "* $N$ - длина каждой вытянутой в вектор feature map $F_{XL}^k$.\n",
    "Обозначим матрицу требуемой размерности $\\hat{F}_{XL}$.\n",
    "\n",
    "**Пояснение:**\n",
    "например, первая строка матрицы $\\hat{F}_{XL}$ соответствует первой feature map $F_{XL}^1$, вытянутой в вектор.\n",
    "\n",
    "Наконец, мы нормализуем матрицу Грама путем деления каждого элемента на число элементов матрицы. \n",
    "\n",
    "**Зачем это нужно?**\n",
    "Такая нормализация нужна потому, что матрицы $\\hat{F}_{XL}$ с большой размерностью $N$ приводят к большим значениям в матрице Грама. Большие значения в свою очередь могут спровоцировать то, что первые сверточные слои (до применения pooling) будут иметь наибольший вклад в процесс градиентного спуска. Но стилевые признаки по большей части содержатся в глубоких слоях нейронной сети, поэтому эта нормализация важна."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CW6WofyC3oJn",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def gram_matrix(input):\n",
    "    a, b, c, d = input.size()  \n",
    "\n",
    "    features = input.view(a * b, c * d)\n",
    "\n",
    "    G = torch.mm(features, features.t()) \n",
    "\n",
    "    return G.div(a * b * c * d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iF1WmBk-3oJo",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Style loss, аналогично content loss, вычисляется через квадрат расстояния между $G_{XL}$ and $G_{SL}$.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2BoLEzjo3oJp",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class StyleLoss(nn.Module):\n",
    "\n",
    "    def __init__(self, target_feature):\n",
    "        super(StyleLoss, self).__init__()\n",
    "        self.target = gram_matrix(target_feature).detach()\n",
    "\n",
    "    def forward(self, input):\n",
    "        G = gram_matrix(input)\n",
    "        self.loss = F.mse_loss(G, self.target)\n",
    "        return input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WGQUQK3m3oJp",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Импортируем модель\n",
    "-------------------\n",
    "\n",
    "Будем использовать предобученную нейронную сеть. Для этой задачи возьмём VGG19.\n",
    "\n",
    "VGG в имплементации pytorch имеет две части:\n",
    "* ``Sequential`` modules: ``features`` (содержит свёртки и пулинги)\n",
    "* ``Classifier`` (содержит полносвязные слои). \n",
    "\n",
    "Мы будем пользоваться модулем ``features``, так как нам нужны результаты применения свёрток для вычисления контентного и стилевого лоссов.\n",
    "\n",
    "Так как мы используем предобученную нейронную сеть и дообучать мы её не планируем, то мы ставим сеть в режим применения: ``.eval()``.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FFwOKIZX3oJq",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cnn = models.vgg19(pretrained=True).features.to(device).eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n0wEb4gz3oJq",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "VGG сети обучены на нормализованных изображениях с параметрами mean=[0.485, 0.456, 0.406] и std=[0.229, 0.224, 0.225].\n",
    "Поэтому перед подачей изображения в сеть его необходимо нормализовать таким же образом.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0i0tQu9o3oJq",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cnn_normalization_mean = torch.tensor([0.485, 0.456, 0.406]).to(device)\n",
    "cnn_normalization_std = torch.tensor([0.229, 0.224, 0.225]).to(device)\n",
    "\n",
    "class Normalization(nn.Module):\n",
    "    def __init__(self, mean, std):\n",
    "        super(Normalization, self).__init__()\n",
    "        self.mean = torch.tensor(mean).view(-1, 1, 1)\n",
    "        self.std = torch.tensor(std).view(-1, 1, 1)\n",
    "\n",
    "    def forward(self, img):\n",
    "        # normalize img\n",
    "        return (img - self.mean) / self.std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lM47IsfQ3oJq",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Теперь мы должны добавить к свёрточной части сети VGG19 стилевой и контентный лосс сразу после свёрточных слоёв.\n",
    "\n",
    "Для этого необходимо создать новый модуль ``Sequential`` с добавленными в нужные места лоссами.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o2D-obcN3oJr",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# пробуйте менять содержимое данных списков. Возможно, это поможет сделать более уникальные картины\n",
    "content_layers_default = ['conv_4']\n",
    "style_layers_default = ['conv_1', 'conv_2', 'conv_3', 'conv_4', 'conv_5']\n",
    "\n",
    "def get_style_model_and_losses(cnn, normalization_mean, normalization_std,\n",
    "                               style_img, content_img,\n",
    "                               content_layers=content_layers_default,\n",
    "                               style_layers=style_layers_default):\n",
    "    cnn = copy.deepcopy(cnn)\n",
    "\n",
    "    normalization = Normalization(normalization_mean, normalization_std).to(device)\n",
    "\n",
    "    content_losses = []\n",
    "    style_losses = []\n",
    "\n",
    "    model = nn.Sequential(normalization)\n",
    "\n",
    "    i = 0 \n",
    "    for layer in cnn.children():\n",
    "        if isinstance(layer, nn.Conv2d):\n",
    "            i += 1\n",
    "            name = 'conv_{}'.format(i)\n",
    "        elif isinstance(layer, nn.ReLU):\n",
    "            name = 'relu_{}'.format(i)\n",
    "            layer = nn.ReLU(inplace=False)\n",
    "        elif isinstance(layer, nn.MaxPool2d):\n",
    "            name = 'pool_{}'.format(i)\n",
    "        elif isinstance(layer, nn.BatchNorm2d):\n",
    "            name = 'bn_{}'.format(i)\n",
    "        else:\n",
    "            raise RuntimeError('Unrecognized layer: {}'.format(layer.__class__.__name__))\n",
    "\n",
    "        model.add_module(name, layer)\n",
    "\n",
    "        if name in content_layers:\n",
    "            target = model(content_img).detach()\n",
    "            content_loss = ContentLoss(target)\n",
    "            model.add_module(\"content_loss_{}\".format(i), content_loss)\n",
    "            content_losses.append(content_loss)\n",
    "\n",
    "        if name in style_layers:\n",
    "            target_feature = model(style_img).detach()\n",
    "            style_loss = StyleLoss(target_feature)\n",
    "            model.add_module(\"style_loss_{}\".format(i), style_loss)\n",
    "            style_losses.append(style_loss)\n",
    "\n",
    "    for i in range(len(model) - 1, -1, -1):\n",
    "        if isinstance(model[i], ContentLoss) or isinstance(model[i], StyleLoss):\n",
    "            break\n",
    "\n",
    "    model = model[:(i + 1)]\n",
    "\n",
    "    return model, style_losses, content_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dr1AySdi3oJs",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Теперь выбираем input image. В качестве input image можно использовать, например, исходное (content) изображение или белый шум.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "UwWCyWu63oJs",
    "outputId": "32b2b739-b104-4bc9-ac84-d10c48197381",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "input_img = content_img.clone()\n",
    "\n",
    "plt.figure()\n",
    "imshow(input_img, title='Input Image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_img = style_img.clone()\n",
    "\n",
    "plt.figure()\n",
    "imshow(test_img, title='Input Image')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KsIi55qQ3oJs",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Градиентный спуск\n",
    "----------------\n",
    "\n",
    "Как предложил автор алгоритма, мы будем использовать алгоритм\n",
    "L-BFGS градиентного спуска. \n",
    "\n",
    "В данной версии алгоритма мы обучаем не веса в сети, а исходное изображение, чтобы минимизировать content/style\n",
    "losses. Для этого используем pytorch ``optim.LBFGS`` и передаем наше изображение (как тензор) в оптимизатор.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TXpJ_Qrk3oJs",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_input_optimizer(input_img):\n",
    "    optimizer = optim.LBFGS([input_img.requires_grad_()])\n",
    "    # Попробуйте другие оптимизаторы, исследуйте, как это влияет на работу алгоритма. \n",
    "    # Однако помните, что LBFGS тут выбран не просто так\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kIJ8MtHz3oJt",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Наконец, создадим функцию, осуществляющую стилевой перенос.\n",
    "* на каждой итерации она получает на вход изображение и вычисляет новые значения лоссов (style/content).\n",
    "* также на каждом шаге с помощью ``backward`` методов динамически вычисляются градиенты функций потерь. \n",
    "\n",
    "Также необходимо привести значения тензоров к отрезку $[0;1]$ на каждой итерации.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4n03flqX3oJt",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def run_style_transfer(cnn, normalization_mean, normalization_std,\n",
    "                       content_img, style_img, input_img, num_steps=300,\n",
    "                       style_weight=1000000, content_weight=1):\n",
    "    \"\"\"Run the style transfer.\"\"\"\n",
    "    print('Building the style transfer model..')\n",
    "    model, style_losses, content_losses = get_style_model_and_losses(cnn,\n",
    "        normalization_mean, normalization_std, style_img, content_img)\n",
    "    optimizer = get_input_optimizer(input_img)\n",
    "\n",
    "    print('Optimizing..')\n",
    "    run = [0]\n",
    "    while run[0] <= num_steps:\n",
    "\n",
    "        def closure():\n",
    "            input_img.data.clamp_(0, 1)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            model(input_img)\n",
    "            style_score = 0\n",
    "            content_score = 0\n",
    "\n",
    "            for sl in style_losses:\n",
    "                style_score += sl.loss\n",
    "            for cl in content_losses:\n",
    "                content_score += cl.loss\n",
    "\n",
    "            style_score *= style_weight\n",
    "            content_score *= content_weight\n",
    "\n",
    "            loss = style_score + content_score\n",
    "            loss.backward()\n",
    "\n",
    "            run[0] += 1\n",
    "            if run[0] % 1 == 0:\n",
    "                print(\"run {}:\".format(run))\n",
    "                print('Style Loss : {:4f} Content Loss: {:4f}'.format(\n",
    "                    style_score.item(), content_score.item()))\n",
    "                print()\n",
    "\n",
    "            return style_score + content_score\n",
    "\n",
    "        optimizer.step(closure)\n",
    "\n",
    "    input_img.data.clamp_(0, 1)\n",
    "\n",
    "    return input_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TYNQr8hY3oJt",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Запускаем алгоритм!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 717
    },
    "id": "sggDPXW33oJt",
    "outputId": "65f82e78-d368-4fb2-cd93-0c19af8c90a1",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "output = run_style_transfer(cnn, cnn_normalization_mean, cnn_normalization_std,\n",
    "                            content_img, test_img, input_img, style_weight=500000,num_steps=20)\n",
    "\n",
    "plt.figure()\n",
    "imshow(output, title='Output Image')\n",
    "\n",
    "# sphinx_gallery_thumbnail_number = 4\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "198DjqpHOXmm",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Задание 1. \n",
    "\n",
    "Мы запустили алгоритм, используя в качестве input_image исходное изображение (content_image). Попробуйте в качестве input_image взять белый шум. Визуализируйте результат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FfJdvqAYOWyz",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#your code here (you can change an existing code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sknp42TJF5RU",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Задание 2.\n",
    "Загрузите другую стилевую картинку (например, \"звездную ночь\" Ван Гога или любую другую), не забудьте привести её к тем же размерам, что и картинка с содержанием.\n",
    "\n",
    "Примените новый стиль к изображению. Нравится ли вам результат?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wvMyzJjuF3N5",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#your code here (you can change an existing code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fkye30ZBGvO_",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Задание 3.\n",
    "Поэкспериментируйте с коэффициентами при style_loss и content_loss (по дефолту используются значения style_weight=1000000, content_weight=1).\n",
    "\n",
    "Выведите на экран итоговые изображения для различных по порядку style_weight (используйте значения весов в диапазоне от 0 до 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4APG85plF3Sg",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#your code here"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Sem1_neural_style",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}