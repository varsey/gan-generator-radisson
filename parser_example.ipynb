{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'images': 195}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "import shutil\n",
    "import requests\n",
    "from threading import Thread\n",
    "from bs4 import BeautifulSoup\n",
    "import argparse\n",
    "\n",
    "unwanted_chars = ['?', '.', '\\\\', '//', ',', '=', '{', '}', '[', ']', '(', ')', '%', '$', '#', '@', '\"', \"'\"]\n",
    "\n",
    "def prettify(string: str) -> str:\n",
    "    for i in unwanted_chars:\n",
    "        string = string.replace(i, '', -1)\n",
    "\n",
    "    return string\n",
    "\n",
    "def get_imagename(string: str) -> str:\n",
    "    string = prettify(string)\n",
    "\n",
    "    if len(string) > 14:\n",
    "        string = string[:10]\n",
    "\n",
    "    if (not (string.endswith('.png') or\n",
    "             string.endswith('.jpg') or\n",
    "             string.endswith('.jpeg'))):\n",
    "        string = string + '.jpg'\n",
    "\n",
    "    return string\n",
    "\n",
    "class ThreadWithReturn(Thread):\n",
    "    def __init__(self, group=None, target=None, name=None, args=(), kwargs={}):\n",
    "        Thread.__init__(self, group, target, name, args, kwargs)\n",
    "        self._return = None\n",
    "\n",
    "    def run(self):\n",
    "        try:\n",
    "            if self._target:\n",
    "                self._return = self._target(*self._args, **self._kwargs)\n",
    "        finally:\n",
    "            del self._target, self._args, self._kwargs\n",
    "\n",
    "    def join(self, timeout=None):\n",
    "        Thread.join(self, timeout)\n",
    "\n",
    "        return self._return\n",
    "\n",
    "\n",
    "\n",
    "def request_handle(url: str, path: str, name: str) -> dict:\n",
    "    \"\"\" Return tags for the picture from different AI Recognition services\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "\n",
    "        if not url or not path or not name:\n",
    "            raise Exception(\"Not enough arguments\")\n",
    "\n",
    "        r = requests.get(url, stream=True)\n",
    "\n",
    "        if r.status_code == 200:\n",
    "            r.raw.decode_content = True\n",
    "\n",
    "            if not name.endswith('.jpg'):\n",
    "                name = name + '.jpg'\n",
    "\n",
    "            path = os.path.join(path, name)\n",
    "\n",
    "            with open(path, 'wb') as f:\n",
    "                shutil.copyfileobj(r.raw, f)\n",
    "\n",
    "            result = {\n",
    "                'images': 1,\n",
    "            }\n",
    "\n",
    "            return result\n",
    "\n",
    "    except Exception as e:\n",
    "        #print(e)\n",
    "        result = {\n",
    "            'images': 0,\n",
    "        }\n",
    "        return result\n",
    "\n",
    "\n",
    "def parse(html_text: str, main_page: str, path: str) -> dict:\n",
    "    \"\"\" Return tags for all pictures on html page\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    img_urls = set()\n",
    "\n",
    "    images = 0\n",
    "\n",
    "    soup = BeautifulSoup(html_text, 'html.parser')\n",
    "    tags = soup.find_all(\"img\")\n",
    "    for tag in tags:\n",
    "        src = tag.get('src') or tag.get('data-src')\n",
    "        if src:\n",
    "            if src.startswith('//'):\n",
    "                src = 'http:' + src\n",
    "            if not src.startswith(\"http\"):\n",
    "                src = main_page + src[1:]\n",
    "            img_urls.add(src)\n",
    "\n",
    "    soup = BeautifulSoup(html_text, 'html.parser')\n",
    "    tags = soup.find_all(\"a\")\n",
    "    for tag in tags:\n",
    "        src = tag.get('src') or tag.get('data-src')\n",
    "        if src and ('.png' in src or '.jpg' in src or '.jpeg' in src):\n",
    "            if src.startswith('//'):\n",
    "                src = 'http:' + src\n",
    "            if not src.startswith(\"http\"):\n",
    "                src = main_page + src[1:]\n",
    "            img_urls.add(src)\n",
    "\n",
    "    links = re.findall('\"((http|ftp)s?://.*?)\"', html_text)\n",
    "    for link in links:\n",
    "        if link and ('.png' in link[0] or '.jpg' in link[0] or '.jpeg' in link[0]):\n",
    "            if link[0].endswith('?'):\n",
    "                img_urls.add(link[0][:-1])\n",
    "            else:\n",
    "                img_urls.add(link[0])\n",
    "\n",
    "    short_links = re.findall('\"(//.*?)\"', html_text)\n",
    "    for link in short_links:\n",
    "        if link and ('.png' in link[0] or '.jpg' in link[0] or '.jpeg' in link[0]):\n",
    "\n",
    "            url = link[0] if link[0].startswith('http') else ('http' + link[0])\n",
    "\n",
    "            if url.endswith('?'):\n",
    "                url = url[:-1]\n",
    "            img_urls.add(url)\n",
    "\n",
    "    threads = []\n",
    "    i = 1\n",
    "    for url in img_urls:\n",
    "        name = f\"{i}-{get_imagename(url.split('/')[-1])}\"\n",
    "        _t = ThreadWithReturn(\n",
    "            target=request_handle,\n",
    "            args=(url, path, name),\n",
    "        )\n",
    "        _t.daemon = True\n",
    "        threads.append(_t)\n",
    "        _t.start()\n",
    "        i += 1\n",
    "\n",
    "    for thread in threads:\n",
    "        _result = thread.join()\n",
    "        if _result:\n",
    "            images += _result['images']\n",
    "\n",
    "    result = {\n",
    "        'images': images,\n",
    "    }\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "response = requests.get(\"https://yandex.ru/images/search?text=геометрия%20пейзаж\", timeout=5)\n",
    "#print(response.text)\n",
    "print(parse(response.text, 'https://yandex.ru/', '.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'images': 193}\n"
     ]
    }
   ],
   "source": [
    "response = requests.get(\"https://yandex.ru/images/search?text=ночной%20чикаго%20фото\", timeout=5)\n",
    "#print(response.text)\n",
    "print(parse(response.text, 'https://yandex.ru/', '.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
