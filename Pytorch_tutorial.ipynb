{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Pytorch, что это такое и почему это удобно?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### В этой тетрадке лежат примеры работы с библиотекой pytorch. Для начала импортируем необходимые нам библиотеки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch # корневая библиотека\n",
    "from torch import nn # библиотека для работы с нейронной сетью\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Создадим тензор из случайных чисел"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5514, 0.7541, 0.5416],\n",
      "        [0.9567, 0.8081, 0.8082],\n",
      "        [0.5377, 0.0822, 0.6788],\n",
      "        [0.2371, 0.1479, 0.1268],\n",
      "        [0.7232, 0.8886, 0.5068]])\n",
      "\n",
      "torch.Size([5, 3])\n",
      "\n",
      "tensor([[[0.8299, 0.5835],\n",
      "         [0.1662, 0.5416],\n",
      "         [0.5501, 0.0864]],\n",
      "\n",
      "        [[0.7668, 0.3552],\n",
      "         [0.9189, 0.3680],\n",
      "         [0.7649, 0.0595]],\n",
      "\n",
      "        [[0.9272, 0.1870],\n",
      "         [0.7438, 0.4530],\n",
      "         [0.8644, 0.6624]],\n",
      "\n",
      "        [[0.2740, 0.9959],\n",
      "         [0.8423, 0.7751],\n",
      "         [0.8324, 0.2864]],\n",
      "\n",
      "        [[0.8214, 0.6231],\n",
      "         [0.1970, 0.9864],\n",
      "         [0.1554, 0.3684]]])\n",
      "\n",
      "torch.Size([5, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(5, 3) # передаем размеры тензора\n",
    "print(x) # содержимое тензора\n",
    "print()\n",
    "print(x.shape) # выведем на экран размеры тензора\n",
    "x = torch.rand(5,3,2)\n",
    "print()\n",
    "print(x) # содержимое тензора\n",
    "print()\n",
    "print(x.shape) # выведем на экран размеры тензора"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Зачастую, при работе с  картинками, мы работам с трехмерными тензорами. Их размености имеют вид (число каналов, высота, ширина). При обучении мы также добавляем еще размерность размера батча, получается (размер батча, число каналов, высота, ширина). Чаще всего в изображениях 3 канала."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Посмотрим на базовые операции с тензорами в Pytorch. Спойлер - они такие же, как и в numpy :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x = torch.rand(5, 3) # создали матрицу\n",
    "y = torch.rand(5, 3) # создали еще одну матрицу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6880, 0.6255, 0.9678],\n",
      "        [0.7534, 0.5214, 0.5582],\n",
      "        [0.5406, 0.4737, 0.6417],\n",
      "        [0.5414, 0.3991, 0.6679],\n",
      "        [0.6909, 0.6236, 0.5681]])\n",
      "\n",
      "tensor([[0.4033, 0.7966, 0.6109],\n",
      "        [0.1041, 0.9199, 0.0078],\n",
      "        [0.8810, 0.9331, 0.2021],\n",
      "        [0.0660, 0.5068, 0.4130],\n",
      "        [0.7891, 0.4109, 0.6786]])\n",
      "\n",
      "tensor([[1.0913, 1.4221, 1.5787],\n",
      "        [0.8575, 1.4413, 0.5660],\n",
      "        [1.4216, 1.4068, 0.8438],\n",
      "        [0.6074, 0.9059, 1.0809],\n",
      "        [1.4800, 1.0345, 1.2467]])\n",
      "\n",
      "tensor([[ 0.2847, -0.1712,  0.3569],\n",
      "        [ 0.6492, -0.3985,  0.5504],\n",
      "        [-0.3405, -0.4594,  0.4395],\n",
      "        [ 0.4753, -0.1077,  0.2549],\n",
      "        [-0.0983,  0.2127, -0.1105]])\n",
      "\n",
      "tensor([[0.2775, 0.4983, 0.5912],\n",
      "        [0.0785, 0.4796, 0.0043],\n",
      "        [0.4763, 0.4420, 0.1297],\n",
      "        [0.0358, 0.2023, 0.2758],\n",
      "        [0.5452, 0.2562, 0.3855]])\n",
      "\n",
      "tensor([[ 1.7060,  0.7851,  1.5843],\n",
      "        [ 7.2339,  0.5668, 71.7559],\n",
      "        [ 0.6136,  0.5076,  3.1746],\n",
      "        [ 8.1971,  0.7875,  1.6173],\n",
      "        [ 0.8755,  1.5176,  0.8371]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(x, end = '\\n\\n')\n",
    "print(y, end = '\\n\\n')\n",
    "print(x+y, end = '\\n\\n') # простое поэлементное сложение\n",
    "print(x-y, end = '\\n\\n') # аналогично поэлементное вычитание\n",
    "print(x*y, end = '\\n\\n') # как вы уже догадались, поэлементное сложение\n",
    "print(x/y, end = '\\n\\n') # не надо иметь три высших образования, чтобы понять, что это поэлементное деление"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Аналогично базовые операции можно проводить и числами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5.6880, 5.6255, 5.9678],\n",
      "        [5.7534, 5.5214, 5.5582],\n",
      "        [5.5406, 5.4737, 5.6417],\n",
      "        [5.5414, 5.3991, 5.6679],\n",
      "        [5.6909, 5.6236, 5.5681]])\n",
      "\n",
      "tensor([[-4.3120, -4.3745, -4.0322],\n",
      "        [-4.2466, -4.4786, -4.4418],\n",
      "        [-4.4594, -4.5263, -4.3583],\n",
      "        [-4.4586, -4.6009, -4.3321],\n",
      "        [-4.3091, -4.3764, -4.4319]])\n",
      "\n",
      "tensor([[3.4402, 3.1273, 4.8390],\n",
      "        [3.7669, 2.6071, 2.7910],\n",
      "        [2.7030, 2.3683, 3.2083],\n",
      "        [2.7069, 1.9956, 3.3395],\n",
      "        [3.4543, 3.1179, 2.8404]])\n",
      "\n",
      "tensor([[0.1376, 0.1251, 0.1936],\n",
      "        [0.1507, 0.1043, 0.1116],\n",
      "        [0.1081, 0.0947, 0.1283],\n",
      "        [0.1083, 0.0798, 0.1336],\n",
      "        [0.1382, 0.1247, 0.1136]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(x+5, end = '\\n\\n')\n",
    "print(x-5, end = '\\n\\n')\n",
    "print(x*5, end = '\\n\\n')\n",
    "print(x/5, end = '\\n\\n') # все аналогично прошлому пункту"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Немного про матричное умножение и операции над тензорами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X*X^T  :\n",
      "tensor([[1.8012, 1.3847, 1.2892, 1.2685, 1.4152],\n",
      "        [1.3847, 1.1510, 1.0124, 0.9888, 1.1627],\n",
      "        [1.2892, 1.0124, 0.9283, 0.9103, 1.0333],\n",
      "        [1.2685, 0.9888, 0.9103, 0.8985, 1.0023],\n",
      "        [1.4152, 1.1627, 1.0333, 1.0023, 1.1889]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"X*X^T  :\\n%s\\n\" % (x@x.T)) # можно и так"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X*X^T  :\n",
      "tensor([[1.8012, 1.3847, 1.2892, 1.2685, 1.4152],\n",
      "        [1.3847, 1.1510, 1.0124, 0.9888, 1.1627],\n",
      "        [1.2892, 1.0124, 0.9283, 0.9103, 1.0333],\n",
      "        [1.2685, 0.9888, 0.9103, 0.8985, 1.0023],\n",
      "        [1.4152, 1.1627, 1.0333, 1.0023, 1.1889]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"X*X^T  :\\n%s\\n\" % (torch.matmul(x, x.transpose(1, 0)))) # а можно так. \n",
    "# Операция transpose очень полезна, если вам надо поменять оси в тензоре местами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Среднее по колонкам :\n",
      "tensor([0.7604, 0.6110, 0.5520, 0.5361, 0.6275])\n",
      "\n",
      "Или по строкам :\n",
      "tensor([0.6428, 0.5286, 0.6807])\n",
      "\n",
      "Изменили размеры :\n",
      "torch.Size([3, 5])\n",
      "\n",
      "Теперь это среднее по строкам :\n",
      "tensor([0.7604, 0.6110, 0.5520, 0.5361, 0.6275])\n",
      "\n",
      "А это по столбцам :\n",
      "tensor([0.6428, 0.5286, 0.6807])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Среднее по колонкам :\\n%s\\n\" % (x.mean(dim=1)))\n",
    "print(\"Или по строкам :\\n%s\\n\" % (x.mean(dim=0)))\n",
    "print(\"Изменили размеры :\\n%s\\n\" % (x.view([3, 5]).shape,))\n",
    "print(\"Теперь это среднее по строкам :\\n%s\\n\" % (x.mean(dim=1)))\n",
    "print(\"А это по столбцам :\\n%s\\n\" % (x.mean(dim=0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Какие еще есть матрицы в pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0000e+00, -3.6893e+19,  0.0000e+00],\n",
      "        [-3.6893e+19,  1.2612e-44,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.empty(5, 3) # пустой тензор\n",
    "print(x) # как видите, не везде стоят чистые нули"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros(5, 3, dtype=torch.long) # тензор с нулями и указанием типов чисел\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.5000, 3.0000])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([5.5, 3]) # конструируем тензор из питоновского листа\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(5, 3, dtype=torch.double) # тензор с единицами и указанием типов чисел\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5, 3])\n"
     ]
    }
   ],
   "source": [
    "print(x.unsqueeze(0).shape) # добавили измерение в начало, аналог броадкастинга"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "print(x.unsqueeze(0).squeeze(0).shape) # убрали измерение в начале, аналог броадкастинга"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Тензор можно вернуть в numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1.],\n",
       "       [1., 1., 1.],\n",
       "       [1., 1., 1.],\n",
       "       [1., 1., 1.],\n",
       "       [1., 1., 1.]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### А можно из numpy в pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.from_numpy(x.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Как в Pytorch работать с данными"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "В pytorch вы можете сами положить свои данные в класс Dataset, чтобы потом по нему итерироваться при обучении. Для этого требуется создать класс-наследник от Dataset и переопределить три метода:\n",
    "\n",
    "__init__ - конструктор класса\n",
    "\n",
    "__getitem__ - метод для выбора элемента по индексу \n",
    "\n",
    "__len__ - метод, который вызывает функция len при применении к объекту класса. Хранит в себе инфорамацию о размере датасета."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class RandomDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"Our random dataset\"\"\"\n",
    "    \n",
    "    def __init__(self, x, y):\n",
    "        # данные можно хранить в полях класса, можно хранить пути к файлам, а можно считывать из файла\n",
    "        # в нашем случае, мы воспользовались первым вариантом\n",
    "        self.x=x\n",
    "        self.y=y\n",
    "        \n",
    "    def __len__(self):\n",
    "        # кол-во элементов в нашем датасете\n",
    "        return len(self.x)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # возвращаем объект и его метку\n",
    "        return torch.tensor(self.x[idx, :], dtype=torch.float), torch.Tensor([self.y[idx]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Создадим игрушечный датасет и посмотрим, как это работает."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x = np.random.rand(1000, 5)\n",
    "y = np.random.rand(1000)\n",
    "\n",
    "dataset = RandomDataset(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.6344, 0.5570, 0.8835, 0.4639, 0.9670]), tensor([0.9626]))"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Для того, чтобы из данных получать батчи в pytorch используется такая сущность как даталоадер, который принимает на вход класс унаследованный от torch.utils.data.Dataset. Сейчас посмотрим на пример:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6351, 0.6254, 0.7428, 0.6986, 0.3789],\n",
      "        [0.0055, 0.5466, 0.7622, 0.7659, 0.1515],\n",
      "        [0.6448, 0.3785, 0.1574, 0.0552, 0.6291],\n",
      "        [0.9667, 0.0413, 0.7778, 0.1618, 0.2848]])\n",
      "\n",
      "tensor([[0.1963],\n",
      "        [0.6494],\n",
      "        [0.6065],\n",
      "        [0.4489]])\n"
     ]
    }
   ],
   "source": [
    "x, y = None, None\n",
    "for batch in dataloader:\n",
    "    x = batch[0]\n",
    "    y = batch[1]\n",
    "print(x)\n",
    "print()\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "В проекте по генерации картин вы будете использовать готовый ImageDataset, в него просто будете передавать путь к папке, где лежат картины. Но полезно знать устройство датасета. В дальнейшем вы сможете обучать свои модели на своих датасетах."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Нейронная сеть"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Нейронные сети в Pytorch можно собирать разными спопобами. Можно делать как в tensorflow и Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = nn.Sequential() # создаем пустую модель, в которую будем добавлять слои\n",
    "model.add_module('l1', nn.Linear(5, 3)) # добавили слой с 5-ю нейронами на вход и 3-мя на выход\n",
    "model.add_module('l2', nn.ReLU()) # добавили функцию активации\n",
    "model.add_module('l3', nn.Linear(3, 1)) # добавили слой с 3-мя нейронами на вход и 5-ю на выход"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4538],\n",
       "        [0.3799],\n",
       "        [0.4934],\n",
       "        [0.4321],\n",
       "        [0.4769],\n",
       "        [0.4617],\n",
       "        [0.5248],\n",
       "        [0.4225],\n",
       "        [0.4704],\n",
       "        [0.4852]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model(torch.rand(10, 5)) # получили предсказания модели на десяти объектах\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Но, чтобы создать сеть с нуля, сделать ее более гибкой, например, с двуми входами или с несколькими выходами, нужно использовать класс Module. Давайте посмотрим, как это делается."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__() # данная строка кода вызывает конструктор родительского класса\n",
    "        self.lin1 = nn.Linear(5, 3) # добавили слой с 5-ю нейронами на вход и 3-мя на выход\n",
    "        self.lin2 = nn.Linear(3, 1) # добавили слой с 3-мя нейронами на вход и 5-ю на выход\n",
    "        self.relu = nn.ReLU() # добавили функцию активации\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.lin1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.lin2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Написанная нами модель идентична той, что мы создали на прошлом шаге, давайте это проилюстрируем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.8420],\n",
       "        [-0.6509],\n",
       "        [-0.6833],\n",
       "        [-0.6978],\n",
       "        [-0.6506],\n",
       "        [-0.6887],\n",
       "        [-0.8794],\n",
       "        [-0.7085],\n",
       "        [-0.8317],\n",
       "        [-0.7801]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model()\n",
    "y_pred = model(torch.rand(10, 5)) # получили предсказания модели на десяти объектах\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Вы можете добавлять свои слои в нейронную сеть. В библиотеке PyTorch их очень много:\n",
    "\n",
    "https://pytorch.org/docs/stable/nn.html\n",
    "\n",
    "Описывать каждый слой было бы очень долгой и бесполезной задачей. Pytorch имеет прекрасную документацию к каждому слою и имеет исчерпывающие примеры. В опытом вы сможете создавать свои уникальные сложные нейронные сети."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Давайте что-то уже обучим!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Обучим нашу собсвтенную модель на классическом MNIST датасете. Загрузим его для начала."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./mnist/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0aba59025a2f4f1caa70134486d4e0a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist/MNIST/raw/train-images-idx3-ubyte.gz to ./mnist/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./mnist/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36b3a41b4311499bb767dce0c6bf9cf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist/MNIST/raw/train-labels-idx1-ubyte.gz to ./mnist/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./mnist/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6013873f7fe4cba83ec13f93638f8f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist/MNIST/raw/t10k-images-idx3-ubyte.gz to ./mnist/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f28ee0ae5bd466fa320bb776643c170",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./mnist/MNIST/raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/caesium/Programming/AnacondaFolder/anaconda3/envs/work/lib/python3.8/site-packages/torchvision/datasets/mnist.py:469: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "\n",
    "mnist_train = torchvision.datasets.MNIST(\n",
    "    './mnist/', train=True, download=True, \n",
    "    transform=torchvision.transforms.ToTensor()\n",
    ") # используем готовый класс от торча для загрузки данных для тренировки\n",
    "\n",
    "mnist_val = torchvision.datasets.MNIST(\n",
    "    './mnist/', train=False, download=True,\n",
    "    transform=torchvision.transforms.ToTensor()\n",
    ") # используем готовый класс от торча для загрузки данных для валидации\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    mnist_train, batch_size=4, shuffle=True, num_workers=1\n",
    ") # так как это уже унаследованный от Dataset класс, его можно сразу пихать в даталоадер\n",
    "\n",
    "val_dataloader = torch.utils.data.DataLoader(\n",
    "    mnist_val, batch_size=4, shuffle=True, num_workers=1\n",
    ") # так как это уже унаследованный от Dataset класс, его можно сразу пихать в даталоадер"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Выведем пару примеров из нашего датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "for i in [0, 1]:\n",
    "    plt.subplot(1, 2, i + 1)\n",
    "    plt.imshow(mnist_train[i][0].squeeze(0).numpy().reshape([28, 28]))\n",
    "    plt.title(str(mnist_train[i][1]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Теперь давайте создадим свою собсвтенную модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class MnistModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MnistModel, self).__init__() # данная строка кода вызывает конструктор родительского класса\n",
    "        self.flatten = nn.Flatten() # данный слой из матрицы 28х28 сделает нам один вектор из 784 чисел\n",
    "        self.lin1 = nn.Linear(784, 128)\n",
    "        self.lin2 = nn.Linear(128, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.lin1(self.flatten(x))\n",
    "        x = self.relu(x)\n",
    "        x = self.lin2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = MnistModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "У модели 101770 параметров\n"
     ]
    }
   ],
   "source": [
    "print('У модели '+str(sum(p.numel() for p in model.parameters()))+' параметров')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Такая небольшая модель у нас получилась. Давайте напишем цикл обучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Чтобы обучать модель, нам нужна функция потерь. \n",
    "# Так как мы решаем задачу классификации, нам нужна перекрестная энтропия\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "# Чтобы делать шаги градиентного спуска, нам нужем оптимизатор\n",
    "# В pytorch есть много видом оптимищации, используем Adam\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, loss: 0.11600582301616669, accuracy: 0.9637\n",
      "Epoch: 2, loss: 0.08768309652805328, accuracy: 0.9746\n",
      "Epoch: 3, loss: 0.10317087173461914, accuracy: 0.9694\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1,4): # всего у нас будет 3 эпохи (3 раза подряд пройдемся по всем батчам из трейна)\n",
    "    for x_train, y_train in train_dataloader: # берем батч из трейн лоадера\n",
    "        y_pred = model(x_train) # делаем предсказания\n",
    "        loss = loss_func(y_pred, y_train) # считаем лосс\n",
    "        loss.backward() # считаем градиенты обратным проходом\n",
    "        optimizer.step() # обновляем параметры сети\n",
    "        optimizer.zero_grad() # обнуляем посчитанные градиенты параметров\n",
    "    \n",
    "    mean_val_loss = [] # сюда будем складывать средний лосс по батчам\n",
    "    val_accuracy = []\n",
    "    with torch.no_grad(): # мы считаем качество, поэтому мы запрещаем фреймворку считать градиенты по параметрам\n",
    "        for x_val, y_val in val_dataloader: # берем батч из вал лоадера\n",
    "            y_pred = model(x_val) # делаем предсказания\n",
    "            loss = nn.CrossEntropyLoss()(y_pred, y_val) # считаем лосс\n",
    "            mean_val_loss.append(loss.numpy()) # добавляем в массив \n",
    "            val_accuracy.extend((torch.argmax(y_pred, dim=-1) == y_val).numpy().tolist())\n",
    "    print('Epoch: {epoch}, loss: {loss}, accuracy: {accuracy}'.format(\n",
    "            epoch=epoch, loss=np.mean(mean_val_loss), accuracy=np.mean(val_accuracy)\n",
    "    )) # выводим статистику"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Как мы можем видеть, уже после первой эпохи наша сеть дает 96% правильных овтетов на валидационной выборке, что не может не радовать! На третьей эпохе мы уже можем видеть эффект переобучения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Подведем кратое резюме того, как нужно обучать нейронные сети в pytorch.\n",
    "\n",
    "1) Создать датасет\n",
    "\n",
    "2) Создать модель\n",
    "\n",
    "3) Задать оптимизатор для модели\n",
    "\n",
    "4) Задать функцию потерь, на минимизацию которой будет обучаться наша модель\n",
    "\n",
    "5) При обучении сначала посчитать функцию потерь на батче\n",
    "\n",
    "6) Подсчитать градиенты\n",
    "\n",
    "7) Сделать шаг оптимизатора\n",
    "\n",
    "8) Обнулить подсчитанные градиенты параметров"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Резюме\n",
    "\n",
    "Теперь вы знакомы с библиотекой pytorch. Узнали про базовые операции над тензорами, узнали, как можно переводить массивы numpy в тензоры на pytorch, научились писать свои датасеты, модели. Научились обучать свои сети на pytorch. \n",
    "\n",
    "Вот хорошая книга по pytorch : https://pytorch.org/assets/deep-learning/Deep-Learning-with-PyTorch.pdf\n",
    "\n",
    "А вот набор туториалов, которые позволят вам глубже познакомиться с pytorch : https://pytorch.org/tutorials/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}